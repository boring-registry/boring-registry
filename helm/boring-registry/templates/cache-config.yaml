{{- if .Values.cachingProxy.enabled }}
apiVersion: v1
kind: ConfigMap
metadata:
  name: nginx-config
  namespace: {{ include "boring-registry.namespace" . }}
  labels:
    {{- include "boring-registry.labels" . | nindent 4 }}
data:
  nginx.conf: |
    worker_processes 1;
    events { worker_connections 2048; } # no of connections of clients + proxy upstream
    pid /tmp/nginx.pid;

    http {
      proxy_cache_path /var/cache/nginx levels=1:2 keys_zone=my_cache:10m max_size={{- .Values.cachingProxy.cache.maxSize }} inactive=60m use_temp_path=off;

      # the API keys/token are used to separate different caches, thus the string `Authentication: Bearer foobar1234` must be cleaned
      # Define the map to replace spaces with underscores
      map $http_authorization $sanitized_auth {
        default "";
        "~^(Bearer\s+(.+))$" "Bearer_$2";
      }

      server {
        listen 8000;

        location / {
          access_log off;
          proxy_cache my_cache;

          # Cache validity settings
          proxy_cache_valid 200 302 {{ .Values.cachingProxy.cache.hit }};
          proxy_cache_valid 404 {{ .Values.cachingProxy.cache.miss }};

          # Cache key including the sanitized authorization header
          proxy_cache_key "$host$request_uri$sanitized_auth";

          # Ignore cache control headers from backend
          proxy_ignore_headers Cache-Control Expires;

          # Revalidate cache on stale
          proxy_cache_revalidate on;

          # Pass all authorization headers to the backend
          proxy_set_header Authorization $http_authorization;

          # Retry mechanism settings
          proxy_next_upstream error timeout invalid_header http_500 http_502 http_503 http_504;
          proxy_next_upstream_tries 3;     # Maximum number of retries
          proxy_next_upstream_timeout 10s; # Timeout for each retry

          # Pass the request to the backend server
          proxy_pass http://localhost:{{ .Values.server.port }};
        }
        # keep metrics internal
        location /metrics {
          access_log off;
          return 302 /;
        }
      }
      server {
        listen 8080;
        location /metrics {
          access_log off;
          # Bypass cache and forward directly to the backend
          proxy_cache_bypass on;
          proxy_no_cache on;
          proxy_pass http://localhost:{{ .Values.server.telemetryPort }};
        }
      }
    }
{{- end }}
